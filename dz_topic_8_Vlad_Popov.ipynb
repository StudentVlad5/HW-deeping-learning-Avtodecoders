{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28328941-97e0-4d23-a4da-3620285444e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "import pandas as pd\n",
    "import glob\n",
    "from PIL import Image\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "088213e9-0148-4c83-a576-e4c6e06856e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Removed 0 empty label files from ./data/train/labels\n",
      "[INFO] Removed 0 empty label files from ./data/val/labels\n"
     ]
    }
   ],
   "source": [
    "# 1. Видалення порожніх .txt файлів з мітками\n",
    "def remove_empty_label_files(folder_path):\n",
    "    count = 0\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.txt'):\n",
    "                full_path = os.path.join(root, file)\n",
    "                if os.stat(full_path).st_size == 0:\n",
    "                    os.remove(full_path)\n",
    "                    count += 1\n",
    "    print(f\"[INFO] Removed {count} empty label files from {folder_path}\")\n",
    "\n",
    "remove_empty_label_files('./data/train/labels')\n",
    "remove_empty_label_files('./data/val/labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45df4f16-2acb-4872-b65c-e18da845c442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Removed 0 bad images from data/train/images\n",
      "[INFO] Removed 0 bad images from data/val/images\n"
     ]
    }
   ],
   "source": [
    "# 2. Видалення зіпсованих або надто малих зображень\n",
    "def remove_bad_images(image_dir):\n",
    "    removed = 0\n",
    "    for img_file in os.listdir(image_dir):\n",
    "        img_path = os.path.join(image_dir, img_file)\n",
    "        try:\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                print(f\"[BAD] Can't read: {img_path} — deleting\")\n",
    "                os.remove(img_path)\n",
    "                removed += 1\n",
    "            else:\n",
    "                h, w = img.shape[:2]\n",
    "                if h < 10 or w < 10:\n",
    "                    print(f\"[BAD] Too small ({w}x{h}): {img_path} — deleting\")\n",
    "                    os.remove(img_path)\n",
    "                    removed += 1\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] {img_path}: {e}\")\n",
    "    print(f\"[INFO] Removed {removed} bad images from {image_dir}\")\n",
    "\n",
    "remove_bad_images('data/train/images')\n",
    "remove_bad_images('data/val/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "199e988d-08f9-41ff-9aeb-a59318f26013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Основна логіка\n",
    "def main():\n",
    "    # 3.1 Створення YAML конфігурації\n",
    "    data_yaml = {\n",
    "        'train': './data/train',\n",
    "        'val': './data/val',\n",
    "        'nc': 10,\n",
    "        'names': [\n",
    "            'door', 'open_door', 'cabinet_door', 'fridge_door',\n",
    "            'window', 'chair', 'table', 'cabinet', 'sofa', 'pillar'\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    if not os.path.exists('indoor.yaml'):\n",
    "        with open('indoor.yaml', 'w') as f:\n",
    "            yaml.dump(data_yaml, f)\n",
    "        print(\"[INFO] Created indoor.yaml\")\n",
    "    else:\n",
    "        print(\"[INFO] indoor.yaml already exists — skipping write.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa15c69a-dc8c-41f1-964d-461123e5302f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading YOLOv9s model...\n"
     ]
    }
   ],
   "source": [
    "# 3.2 Завантаження моделі\n",
    "print(\"[INFO] Loading YOLOv9s model...\")\n",
    "model = YOLO('yolov9s.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5ef7837-8492-4987-b75d-7a56669a5045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting training...\n",
      "New https://pypi.org/project/ultralytics/8.3.169 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.167  Python-3.12.6 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce GTX 1050, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=indoor.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov9s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=indoor_yolov9s63, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs\\detect\\indoor_yolov9s63, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=0, workspace=None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\IT_courses\\GOIT\\Python\\Pandas\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-07-24 11:39:53,221\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-07-24 11:39:55,952\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     31104  ultralytics.nn.modules.block.ELAN1           [64, 64, 64, 32]              \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.block.AConv           [64, 128]                     \n",
      "  4                  -1  1    258432  ultralytics.nn.modules.block.RepNCSPELAN4    [128, 128, 128, 64, 3]        \n",
      "  5                  -1  1    221568  ultralytics.nn.modules.block.AConv           [128, 192]                    \n",
      "  6                  -1  1    579648  ultralytics.nn.modules.block.RepNCSPELAN4    [192, 192, 192, 96, 3]        \n",
      "  7                  -1  1    442880  ultralytics.nn.modules.block.AConv           [192, 256]                    \n",
      "  8                  -1  1   1028864  ultralytics.nn.modules.block.RepNCSPELAN4    [256, 256, 256, 128, 3]       \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPELAN         [256, 256, 128]               \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    628800  ultralytics.nn.modules.block.RepNCSPELAN4    [448, 192, 192, 96, 3]        \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    283008  ultralytics.nn.modules.block.RepNCSPELAN4    [320, 128, 128, 64, 3]        \n",
      " 16                  -1  1    110784  ultralytics.nn.modules.block.AConv           [128, 96]                     \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    598080  ultralytics.nn.modules.block.RepNCSPELAN4    [288, 192, 192, 96, 3]        \n",
      " 19                  -1  1    221440  ultralytics.nn.modules.block.AConv           [192, 128]                    \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1061632  ultralytics.nn.modules.block.RepNCSPELAN4    [384, 256, 256, 128, 3]       \n",
      " 22        [15, 18, 21]  1   1566958  ultralytics.nn.modules.head.Detect           [10, [128, 192, 256]]         \n",
      "YOLOv9s summary: 544 layers, 7,291,278 parameters, 7,291,262 gradients, 27.4 GFLOPs\n",
      "\n",
      "Transferred 1333/1339 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 475.7331.4 MB/s, size: 195.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\IT_courses\\GOIT\\Python\\Pandas\\data\\train\\labels.cache... 892 images, 120 backgrounds, 0 corrupt: 100%|██████████| 1012/1012 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 456.9116.9 MB/s, size: 217.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\IT_courses\\GOIT\\Python\\Pandas\\data\\val\\labels.cache... 199 images, 31 backgrounds, 0 corrupt: 100%|██████████| 230/230 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\indoor_yolov9s63\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 221 weight(decay=0.0), 228 weight(decay=0.0005), 227 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\indoor_yolov9s63\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50      5.44G      1.684      3.051      1.638         58        640: 100%|██████████| 64/64 [19:22<00:00, 18.16s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:24<00:00,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289      0.565      0.303      0.279      0.156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50      5.46G      1.486       1.89      1.447         37        640: 100%|██████████| 64/64 [18:27<00:00, 17.30s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:13<00:00,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289      0.512      0.286      0.217      0.121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50      5.43G      1.502      1.864      1.468         33        640: 100%|██████████| 64/64 [17:20<00:00, 16.26s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:39<00:00,  4.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289      0.525      0.235      0.214       0.12\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50      5.43G      1.477      1.783      1.451         27        640: 100%|██████████| 64/64 [18:14<00:00, 17.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:18<00:00,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289      0.387      0.354      0.186      0.103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50      5.43G      1.494      1.736      1.454         31        640: 100%|██████████| 64/64 [19:06<00:00, 17.91s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:16<00:00,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289      0.596      0.256      0.243      0.135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50      5.43G       1.43      1.643      1.426         27        640: 100%|██████████| 64/64 [17:47<00:00, 16.68s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:17<00:00,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289      0.429      0.286      0.256       0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50      5.43G       1.42      1.614      1.413         39        640: 100%|██████████| 64/64 [17:29<00:00, 16.40s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:14<00:00,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289      0.475      0.304      0.264      0.152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50      5.43G      1.413      1.567      1.412         20        640: 100%|██████████| 64/64 [18:04<00:00, 16.94s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:14<00:00,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289      0.606      0.276       0.29      0.169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50      5.43G      1.407      1.507      1.405         49        640: 100%|██████████| 64/64 [17:28<00:00, 16.38s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:15<00:00,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289      0.473      0.262      0.265      0.156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50      5.43G      1.393      1.485      1.411         43        640: 100%|██████████| 64/64 [17:42<00:00, 16.61s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:18<00:00,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289       0.74      0.272      0.319      0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50      5.43G      1.363      1.427      1.392         23        640: 100%|██████████| 64/64 [16:16<00:00, 15.26s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:13<00:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289      0.497      0.356      0.327       0.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50      5.44G      1.353      1.404      1.377         12        640: 100%|██████████| 64/64 [17:39<00:00, 16.56s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:15<00:00,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289      0.484      0.299      0.301      0.167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/50      5.43G       1.33       1.33      1.362         18        640: 100%|██████████| 64/64 [17:31<00:00, 16.42s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:18<00:00,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289      0.562      0.303      0.314      0.177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50      5.43G      1.317      1.292      1.356         37        640: 100%|██████████| 64/64 [17:17<00:00, 16.21s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:13<00:00,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289      0.419      0.389      0.358       0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50      5.43G      1.302      1.262      1.339         45        640: 100%|██████████| 64/64 [16:59<00:00, 15.93s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:14<00:00,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289      0.513       0.33      0.335      0.196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/50      5.43G      1.324      1.283      1.347         48        640: 100%|██████████| 64/64 [17:33<00:00, 16.47s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:13<00:00,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289      0.452      0.343      0.339        0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/50      5.55G      1.307      1.221      1.339         28        640: 100%|██████████| 64/64 [17:33<00:00, 16.46s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:13<00:00,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289       0.51      0.327      0.345      0.204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50      5.43G      1.261      1.161      1.323         29        640: 100%|██████████| 64/64 [17:28<00:00, 16.38s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:13<00:00,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289      0.658      0.337      0.361      0.213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/50      5.43G      1.286      1.177       1.33         37        640: 100%|██████████| 64/64 [17:33<00:00, 16.46s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:13<00:00,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289      0.374      0.406      0.339      0.201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/50      5.43G      1.255      1.155      1.325         65        640: 100%|██████████| 64/64 [17:37<00:00, 16.53s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:13<00:00,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289      0.468      0.346      0.367      0.219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50      5.43G      1.253      1.109      1.311         27        640: 100%|██████████| 64/64 [17:01<00:00, 15.96s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:13<00:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289      0.593      0.307      0.352      0.216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/50      5.43G      1.233      1.087      1.298         57        640: 100%|██████████| 64/64 [17:21<00:00, 16.27s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:13<00:00,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289       0.42      0.343      0.385      0.226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/50      5.43G      1.237      1.087      1.284         36        640: 100%|██████████| 64/64 [17:09<00:00, 16.09s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:18<00:00,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289      0.544      0.416      0.455      0.273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/50      5.43G      1.204      1.019      1.263         24        640: 100%|██████████| 64/64 [19:04<00:00, 17.89s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:20<00:00,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289      0.378      0.493      0.412      0.256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/50      5.43G      1.208      0.994      1.277         51        640: 100%|██████████| 64/64 [17:20<00:00, 16.26s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:19<00:00,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289      0.497      0.366      0.385       0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/50      5.43G      1.204       1.01      1.286         21        640: 100%|██████████| 64/64 [17:01<00:00, 15.97s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:17<00:00,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289      0.361      0.355       0.37      0.224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/50      5.44G        1.2     0.9782      1.272         23        640: 100%|██████████| 64/64 [17:13<00:00, 16.14s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:17<00:00,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289       0.38       0.56      0.477      0.304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50      5.43G      1.177     0.9571      1.253         38        640: 100%|██████████| 64/64 [17:24<00:00, 16.33s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:20<00:00,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289      0.454      0.365       0.37      0.226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/50      5.44G      1.153     0.9336      1.245         17        640: 100%|██████████| 64/64 [16:50<00:00, 15.79s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:17<00:00,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289      0.485      0.482      0.444      0.262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/50      5.43G      1.153     0.8992      1.256         48        640: 100%|██████████| 64/64 [16:58<00:00, 15.91s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:16<00:00,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289      0.453      0.355      0.398      0.235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/50      5.44G      1.123     0.8678      1.227          9        640: 100%|██████████| 64/64 [17:01<00:00, 15.96s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:10<00:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289      0.473      0.496      0.391      0.241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/50      5.43G      1.151     0.8974      1.242         48        640: 100%|██████████| 64/64 [17:33<00:00, 16.46s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:12<00:00,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289      0.528      0.431      0.447      0.273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/50      5.43G      1.123     0.8748       1.22         75        640: 100%|██████████| 64/64 [16:06<00:00, 15.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:12<00:00,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289      0.419      0.401      0.408       0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/50      5.43G      1.091     0.8384      1.217         22        640: 100%|██████████| 64/64 [16:57<00:00, 15.90s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:11<00:00,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289      0.378      0.399      0.397      0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/50      5.43G       1.11     0.8296      1.212         34        640: 100%|██████████| 64/64 [16:31<00:00, 15.49s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:12<00:00,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289      0.399      0.402      0.386      0.238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/50      5.43G      1.095     0.8067      1.216         59        640: 100%|██████████| 64/64 [16:07<00:00, 15.12s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:10<00:00,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289      0.483      0.496      0.405      0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/50      5.43G      1.082     0.7829      1.199         70        640: 100%|██████████| 64/64 [15:58<00:00, 14.97s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:13<00:00,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289      0.499       0.41      0.421       0.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/50      5.43G      1.064      0.768       1.18         37        640: 100%|██████████| 64/64 [15:58<00:00, 14.98s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:12<00:00,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289       0.51      0.368      0.403       0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/50      5.43G      1.074     0.7628      1.205         18        640: 100%|██████████| 64/64 [15:43<00:00, 14.74s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:12<00:00,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289      0.421      0.524      0.426      0.263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/50      5.43G      1.035     0.7441      1.179         27        640: 100%|██████████| 64/64 [15:40<00:00, 14.69s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:12<00:00,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289      0.389      0.548      0.415      0.252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/50      5.43G      1.066     0.7364      1.196         31        640: 100%|██████████| 64/64 [15:50<00:00, 14.86s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:12<00:00,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289       0.47      0.408      0.406      0.247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/50      5.43G      1.008     0.6328      1.179          5        640: 100%|██████████| 64/64 [15:40<00:00, 14.69s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:10<00:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289       0.45      0.395      0.408      0.244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/50      5.43G      1.013     0.6131      1.168         24        640: 100%|██████████| 64/64 [15:39<00:00, 14.68s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:10<00:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289      0.465      0.396      0.397      0.244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/50      5.43G     0.9997     0.5906       1.17         25        640: 100%|██████████| 64/64 [15:31<00:00, 14.55s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:12<00:00,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289      0.446      0.519      0.424      0.253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/50      5.43G     0.9889     0.5821      1.155         27        640: 100%|██████████| 64/64 [15:27<00:00, 14.50s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:10<00:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289      0.443      0.522      0.449      0.254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/50      5.43G     0.9751     0.5591      1.144         10        640: 100%|██████████| 64/64 [15:03<00:00, 14.12s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:10<00:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289      0.455      0.399      0.414       0.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/50      5.44G     0.9685     0.5519      1.146          7        640: 100%|██████████| 64/64 [15:45<00:00, 14.77s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:13<00:00,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289      0.531      0.393       0.43      0.256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/50      5.43G     0.9585     0.5599      1.136         16        640: 100%|██████████| 64/64 [15:40<00:00, 14.70s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:13<00:00,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289      0.453       0.53      0.449      0.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/50      5.44G     0.9463      0.531      1.131         11        640: 100%|██████████| 64/64 [16:01<00:00, 15.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:12<00:00,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289      0.529      0.512       0.46      0.275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/50      5.43G     0.9282     0.5164      1.124         32        640: 100%|██████████| 64/64 [16:02<00:00, 15.04s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:10<00:00,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289      0.509      0.499      0.456      0.276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "50 epochs completed in 14.414 hours.\n",
      "Optimizer stripped from runs\\detect\\indoor_yolov9s63\\weights\\last.pt, 15.2MB\n",
      "Optimizer stripped from runs\\detect\\indoor_yolov9s63\\weights\\best.pt, 15.2MB\n",
      "\n",
      "Validating runs\\detect\\indoor_yolov9s63\\weights\\best.pt...\n",
      "Ultralytics 8.3.167  Python-3.12.6 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce GTX 1050, 4096MiB)\n",
      "YOLOv9s summary (fused): 197 layers, 7,170,958 parameters, 0 gradients, 26.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:10<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289       0.38      0.562      0.478      0.304\n",
      "                  door         63         97      0.355      0.639      0.505      0.317\n",
      "             open_door         99        765      0.625      0.816      0.808      0.464\n",
      "          cabinet_door         85        192      0.616      0.714      0.684      0.466\n",
      "           fridge_door         39         91      0.313      0.455      0.293      0.175\n",
      "                window         24         49      0.467      0.633      0.613      0.342\n",
      "                 chair         30         40      0.195      0.425      0.245      0.135\n",
      "                 table         28         32      0.262      0.594      0.475      0.288\n",
      "               cabinet          1          1      0.794          1      0.995      0.796\n",
      "                  sofa         13         13      0.064      0.231     0.0922     0.0372\n",
      "                pillar          4          9      0.111      0.111     0.0727     0.0248\n",
      "Speed: 0.6ms preprocess, 26.4ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\indoor_yolov9s63\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 3.3 Тренування\n",
    "print(\"[INFO] Starting training...\")\n",
    "results = model.train(\n",
    "    data='indoor.yaml',\n",
    "    epochs=50,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    name='indoor_yolov9s6',\n",
    "    device=0,      # GPU (або 'cpu')\n",
    "    workers=0      # важливо для Windows!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b00f4c5-8791-477c-91b5-02c61b544a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3.4 Побудова графіків метрик\n",
    "csv_path = 'runs/detect/indoor_yolov9s63/results.csv'\n",
    "if os.path.exists(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    # Вибираємо наявні метрики для графіку\n",
    "    metrics_to_plot = [\n",
    "        'metrics/mAP50(B)', \n",
    "        'metrics/precision(B)', \n",
    "        'metrics/recall(B)'\n",
    "    ]\n",
    "\n",
    "    # Побудова графіку\n",
    "    df[metrics_to_plot].plot(figsize=(10, 6), title='Training Metrics')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"[WARNING] results.csv not found. Skipping metric plots.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd089269-8af3-41b6-bb3c-b9fb07efff12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Running validation...\n",
      "Ultralytics 8.3.167  Python-3.12.6 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce GTX 1050, 4096MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 828.9515.5 MB/s, size: 198.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\IT_courses\\GOIT\\Python\\Pandas\\data\\val\\labels.cache... 199 images, 31 backgrounds, 0 corrupt: 100%|██████████| 230/230 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        230       1289      0.385      0.567       0.48      0.305\n",
      "                  door         63         97       0.35      0.629      0.504      0.316\n",
      "             open_door         99        765      0.631      0.818      0.811      0.465\n",
      "          cabinet_door         85        192       0.61      0.714      0.682      0.464\n",
      "           fridge_door         39         91      0.311       0.44       0.29      0.174\n",
      "                window         24         49      0.477      0.653      0.615      0.347\n",
      "                 chair         30         40      0.206       0.45      0.249      0.132\n",
      "                 table         28         32      0.281      0.625      0.489      0.294\n",
      "               cabinet          1          1      0.803          1      0.995      0.796\n",
      "                  sofa         13         13     0.0641      0.231     0.0926     0.0374\n",
      "                pillar          4          9      0.112      0.111     0.0729     0.0248\n",
      "Speed: 0.6ms preprocess, 29.5ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\indoor_yolov9s6311\u001b[0m\n",
      "[INFO] Running prediction and collecting labels...\n",
      "[INFO] Building confusion matrix...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Plotting class-wise metrics...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "\n",
    "# 3.5 Оцінка моделі\n",
    "# Валідація\n",
    "print(\"[INFO] Running validation...\")\n",
    "metrics = model.val()\n",
    "\n",
    "# Шляхи\n",
    "val_img_dir = './data/val/images'\n",
    "val_label_dir = './data/val/labels'\n",
    "\n",
    "image_paths = sorted(glob.glob(os.path.join(val_img_dir, '*.jpg')))\n",
    "label_paths = sorted(glob.glob(os.path.join(val_label_dir, '*.txt')))\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "print(\"[INFO] Running prediction and collecting labels...\")\n",
    "for img_path, lbl_path in zip(image_paths, label_paths):\n",
    "    with open(lbl_path, 'r') as f:\n",
    "        label_line = f.readline()\n",
    "        if not label_line:\n",
    "            continue\n",
    "        true_class = int(label_line.split()[0])\n",
    "        y_true.append(true_class)\n",
    "\n",
    "    result = model.predict(img_path, conf=0.25, iou=0.5, save=False, verbose=False)[0]\n",
    "\n",
    "    if len(result.boxes) > 0:\n",
    "        pred_class = int(result.boxes.cls[0].item())\n",
    "    else:\n",
    "        pred_class = -1  # нічого не знайдено\n",
    "\n",
    "    y_pred.append(pred_class)\n",
    "\n",
    "# Видаляємо випадки без передбачення (-1)\n",
    "y_true_filtered = []\n",
    "y_pred_filtered = []\n",
    "for yt, yp in zip(y_true, y_pred):\n",
    "    if yp != -1:\n",
    "        y_true_filtered.append(yt)\n",
    "        y_pred_filtered.append(yp)\n",
    "\n",
    "# Завантаження класів\n",
    "with open('indoor.yaml', 'r') as f:\n",
    "    class_names = yaml.safe_load(f)['names']\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Побудова confusion matrix (з фіксованою кількістю класів)\n",
    "print(\"[INFO] Building confusion matrix...\")\n",
    "cm = confusion_matrix(y_true_filtered, y_pred_filtered, labels=list(range(num_classes)))\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "disp.plot(include_values=True, xticks_rotation=45, cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Візуалізація метрик по класах\n",
    "print(\"[INFO] Plotting class-wise metrics...\")\n",
    "def pad_list(arr, length, fill=0.0):\n",
    "    arr = np.array(arr)\n",
    "    if arr.size < length:\n",
    "        padded = np.pad(arr, (0, length - arr.size), constant_values=fill)\n",
    "        return padded.tolist()\n",
    "    else:\n",
    "        return arr.tolist()\n",
    "\n",
    "precision = pad_list(metrics.box.p, num_classes)\n",
    "recall = pad_list(metrics.box.r, num_classes)\n",
    "f1 = pad_list(metrics.box.f1, num_classes)\n",
    "ap = pad_list(metrics.box.ap, num_classes)\n",
    "\n",
    "x = np.arange(num_classes)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(x, precision, marker='o', label='Precision')\n",
    "plt.plot(x, recall, marker='s', label='Recall')\n",
    "plt.plot(x, f1, marker='^', label='F1-score')\n",
    "plt.plot(x, ap, marker='x', label='mAP')\n",
    "\n",
    "plt.xticks(x, class_names, rotation=45)\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Metric Value\")\n",
    "plt.title(\"Class-wise Metrics\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3317ca1a-3134-4b6c-8dd1-284dd76da9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Model saved at: yolov9s.pt\n"
     ]
    }
   ],
   "source": [
    "# 3.6 Збереження фінальної моделі\n",
    "best_weights = getattr(model, 'ckpt_path', 'runs/detect/indoor_yolov9s6/weights/best.pt')\n",
    "print(f\"[INFO] Model saved at: {best_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a89879f-1374-4243-a6bd-37653a883ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Running predictions on test images...\n",
      "\n",
      "image 1/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1003.png: 480x640 2 open_doors, 128.3ms\n",
      "image 2/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1014.png: 480x640 (no detections), 77.2ms\n",
      "image 3/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1015.png: 480x640 (no detections), 75.6ms\n",
      "image 4/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1020.png: 480x640 (no detections), 71.8ms\n",
      "image 5/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1021.png: 480x640 (no detections), 76.5ms\n",
      "image 6/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1023.png: 480x640 1 fridge_door, 1 window, 70.9ms\n",
      "image 7/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1026.png: 480x640 1 door, 1 open_door, 2 fridge_doors, 2 cabinets, 74.0ms\n",
      "image 8/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1027.png: 480x640 1 window, 1 cabinet, 70.3ms\n",
      "image 9/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1028.png: 480x640 1 window, 2 chairs, 1 cabinet, 1 sofa, 68.9ms\n",
      "image 10/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1029.png: 480x640 4 open_doors, 1 table, 83.7ms\n",
      "image 11/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1032.png: 480x640 (no detections), 76.0ms\n",
      "image 12/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1034.png: 480x640 1 door, 3 open_doors, 1 window, 82.3ms\n",
      "image 13/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1040.png: 480x640 3 open_doors, 2 windows, 83.8ms\n",
      "image 14/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1043.png: 480x640 4 open_doors, 1 table, 82.2ms\n",
      "image 15/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1045.png: 480x640 (no detections), 79.9ms\n",
      "image 16/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1047.png: 480x640 2 open_doors, 1 chair, 70.0ms\n",
      "image 17/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1048.png: 480x640 1 table, 70.4ms\n",
      "image 18/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1052.png: 480x640 (no detections), 69.9ms\n",
      "image 19/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1054.png: 480x640 1 open_door, 1 window, 1 chair, 74.5ms\n",
      "image 20/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1055.png: 480x640 5 open_doors, 1 table, 63.8ms\n",
      "image 21/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1058.png: 480x640 1 open_door, 1 window, 64.5ms\n",
      "image 22/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1065.png: 480x640 8 open_doors, 1 table, 102.6ms\n",
      "image 23/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1069.png: 480x640 2 open_doors, 1 fridge_door, 1 window, 87.9ms\n",
      "image 24/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1071.png: 480x640 (no detections), 73.1ms\n",
      "image 25/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1079.png: 480x640 1 fridge_door, 2 windows, 70.2ms\n",
      "image 26/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1081.png: 480x640 1 open_door, 2 windows, 1 chair, 69.2ms\n",
      "image 27/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1089.png: 480x640 1 fridge_door, 71.1ms\n",
      "image 28/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\109.png: 480x640 1 window, 1 pillar, 64.0ms\n",
      "image 29/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1093.png: 480x640 (no detections), 64.3ms\n",
      "image 30/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1095.png: 480x640 (no detections), 65.6ms\n",
      "image 31/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\110.png: 480x640 1 chair, 67.4ms\n",
      "image 32/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1101.png: 480x640 (no detections), 75.2ms\n",
      "image 33/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1104.png: 480x640 (no detections), 100.2ms\n",
      "image 34/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1111.png: 480x640 1 fridge_door, 3 chairs, 1 sofa, 1 pillar, 77.6ms\n",
      "image 35/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1112.png: 480x640 2 open_doors, 1 fridge_door, 1 window, 1 chair, 69.1ms\n",
      "image 36/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1113.png: 480x640 1 door, 69.4ms\n",
      "image 37/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1116.png: 480x640 (no detections), 69.1ms\n",
      "image 38/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1119.png: 480x640 (no detections), 63.2ms\n",
      "image 39/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1122.png: 480x640 (no detections), 63.6ms\n",
      "image 40/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1123.png: 480x640 3 open_doors, 1 cabinet_door, 1 table, 64.3ms\n",
      "image 41/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1125.png: 480x640 3 open_doors, 1 window, 1 table, 73.8ms\n",
      "image 42/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1133.png: 480x640 (no detections), 63.9ms\n",
      "image 43/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1137.png: 480x640 1 window, 72.2ms\n",
      "image 44/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1138.png: 480x640 1 fridge_door, 1 window, 74.2ms\n",
      "image 45/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1139.png: 480x640 (no detections), 67.0ms\n",
      "image 46/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1145.png: 480x640 6 open_doors, 1 cabinet_door, 1 table, 71.9ms\n",
      "image 47/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1154.png: 480x640 (no detections), 62.9ms\n",
      "image 48/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1158.png: 480x640 3 open_doors, 64.0ms\n",
      "image 49/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\116.png: 480x640 (no detections), 63.3ms\n",
      "image 50/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1160.png: 480x640 1 open_door, 63.1ms\n",
      "image 51/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1167.png: 480x640 1 door, 3 open_doors, 59.7ms\n",
      "image 52/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1171.png: 480x640 1 open_door, 1 table, 60.5ms\n",
      "image 53/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1174.png: 480x640 (no detections), 66.1ms\n",
      "image 54/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1176.png: 480x640 1 table, 80.9ms\n",
      "image 55/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\118.png: 480x640 3 windows, 81.2ms\n",
      "image 56/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1186.png: 480x640 1 fridge_door, 72.3ms\n",
      "image 57/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1187.png: 480x640 1 open_door, 1 window, 72.3ms\n",
      "image 58/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1195.png: 480x640 2 open_doors, 79.7ms\n",
      "image 59/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\12.png: 480x640 (no detections), 68.6ms\n",
      "image 60/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1206.png: 480x640 2 fridge_doors, 69.3ms\n",
      "image 61/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1207.png: 480x640 (no detections), 63.1ms\n",
      "image 62/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1209.png: 480x640 2 windows, 72.5ms\n",
      "image 63/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1217.png: 480x640 (no detections), 77.2ms\n",
      "image 64/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1232.png: 480x640 (no detections), 69.7ms\n",
      "image 65/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1239.png: 480x640 (no detections), 82.5ms\n",
      "image 66/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\124.png: 480x640 1 chair, 116.2ms\n",
      "image 67/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1245.png: 480x640 1 fridge_door, 73.4ms\n",
      "image 68/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1251.png: 480x640 4 open_doors, 1 sofa, 72.9ms\n",
      "image 69/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1253.png: 480x640 1 cabinet, 69.5ms\n",
      "image 70/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1256.png: 480x640 1 door, 71.0ms\n",
      "image 71/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\126.png: 480x640 7 open_doors, 2 cabinet_doors, 70.6ms\n",
      "image 72/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1269.png: 480x640 3 fridge_doors, 64.0ms\n",
      "image 73/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\127.png: 480x640 6 open_doors, 2 windows, 66.8ms\n",
      "image 74/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1278.png: 480x640 (no detections), 73.0ms\n",
      "image 75/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1280.png: 480x640 2 open_doors, 2 fridge_doors, 2 windows, 67.5ms\n",
      "image 76/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1281.png: 480x640 1 chair, 103.1ms\n",
      "image 77/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1287.png: 480x640 1 door, 3 open_doors, 70.4ms\n",
      "image 78/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1290.png: 480x640 1 fridge_door, 1 window, 1 chair, 69.7ms\n",
      "image 79/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1295.png: 480x640 (no detections), 70.6ms\n",
      "image 80/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1300.png: 480x640 (no detections), 69.0ms\n",
      "image 81/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1302.png: 480x640 1 fridge_door, 62.0ms\n",
      "image 82/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1310.png: 480x640 3 open_doors, 78.2ms\n",
      "image 83/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1311.png: 480x640 (no detections), 71.9ms\n",
      "image 84/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1315.png: 480x640 1 door, 1 cabinet, 63.3ms\n",
      "image 85/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1320.png: 480x640 (no detections), 62.3ms\n",
      "image 86/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1323.png: 480x640 4 open_doors, 64.8ms\n",
      "image 87/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1329.png: 480x640 1 chair, 75.2ms\n",
      "image 88/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\133.png: 480x640 2 open_doors, 66.5ms\n",
      "image 89/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1333.png: 480x640 (no detections), 76.1ms\n",
      "image 90/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1337.png: 480x640 (no detections), 63.9ms\n",
      "image 91/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1338.png: 480x640 1 open_door, 3 fridge_doors, 61.9ms\n",
      "image 92/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1339.png: 480x640 1 fridge_door, 1 chair, 64.3ms\n",
      "image 93/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1342.png: 480x640 4 open_doors, 1 table, 67.7ms\n",
      "image 94/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1344.png: 480x640 1 fridge_door, 1 window, 64.8ms\n",
      "image 95/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1345.png: 480x640 1 door, 2 open_doors, 1 window, 1 chair, 1 table, 69.1ms\n",
      "image 96/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1352.png: 480x640 1 sofa, 66.8ms\n",
      "image 97/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1357.png: 480x640 (no detections), 75.4ms\n",
      "image 98/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\1382.png: 480x640 5 open_doors, 1 window, 91.7ms\n",
      "image 99/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\831.png: 480x640 2 open_doors, 1 window, 76.9ms\n",
      "image 100/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\888.png: 480x640 2 fridge_doors, 2 windows, 68.5ms\n",
      "image 101/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\908.png: 480x640 5 open_doors, 68.5ms\n",
      "image 102/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\921.png: 480x640 1 table, 1 sofa, 61.5ms\n",
      "image 103/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\923.png: 480x640 (no detections), 68.6ms\n",
      "image 104/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\925.png: 480x640 (no detections), 67.7ms\n",
      "image 105/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\954.png: 480x640 2 fridge_doors, 1 window, 1 chair, 63.5ms\n",
      "image 106/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\998.png: 480x640 2 open_doors, 1 chair, 1 table, 62.6ms\n",
      "image 107/107 d:\\IT_courses\\GOIT\\Python\\Pandas\\data\\test\\images\\999.png: 480x640 2 open_doors, 1 window, 59.6ms\n",
      "Speed: 5.3ms preprocess, 72.2ms inference, 4.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\indoor_yolov9s633\u001b[0m\n",
      "[INFO] Predictions saved to runs/detect/predict/\n"
     ]
    }
   ],
   "source": [
    "# 3.7 Тестування на нових зображеннях\n",
    "if os.path.exists('data/test/images/'):\n",
    "    print(\"[INFO] Running predictions on test images...\")\n",
    "    model.predict('data/test/images/', save=True, conf=0.4)\n",
    "    print(\"[INFO] Predictions saved to runs/detect/predict/\")\n",
    "else:\n",
    "    print(\"[WARNING] Test image folder not found. Skipping prediction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93707e2e-34cd-46a1-93f9-b8eb7ad97495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Showing prediction preview: runs/detect/indoor_yolov9s633\\1003.jpg\n"
     ]
    }
   ],
   "source": [
    "# 3.8 Відкриття першого передбаченого зображення (опціонально)\n",
    "pred_images = sorted(glob.glob('runs/detect/indoor_yolov9s633/*.jpg'))\n",
    "if pred_images:\n",
    "    print(f\"[INFO] Showing prediction preview: {pred_images[0]}\")\n",
    "    img = Image.open(pred_images[0])\n",
    "    img.show()\n",
    "else:\n",
    "    print(\"[INFO] No predicted images found to display.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57560149-5dfd-428a-a80b-f48f125cf6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] indoor.yaml already exists — skipping write.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import multiprocessing\n",
    "    multiprocessing.freeze_support()  # Для Windows\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n1. Аналіз отриманих результатів\\n1 навчання\\n\\nМетрика\\t      Значення\\nmAP@0.5\\t        0.48\\nmAP@0.5:0.95\\t0.305\\nPrecision (P)\\t0.385\\nRecall (R)\\t    0.567\\n\\n2 навчання\\nМетрика\\t        Значення\\nmAP@0.5\\t        0.48\\nmAP@0.5:0.95\\t0.304\\nPrecision (P)\\t0.385\\nRecall (R)\\t    0.567\\n\\n\\nКлас\\t          P\\t    R\\t    mAP@0.5\\tmAP@0.5:0.95\\nopen_door\\t    0.631\\t0.818\\t0.811\\t0.465 ✅\\ncabinet_door\\t0.610\\t0.714\\t0.682\\t0.464 ✅\\nwindow\\t        0.477\\t0.653\\t0.615\\t0.347 👍\\ntable\\t        0.281\\t0.625\\t0.489\\t0.294\\ndoor\\t        0.35\\t0.629\\t0.504\\t0.316\\nfridge_door\\t    0.311\\t0.44\\t0.29\\t0.174 🔻\\nchair\\t        0.206\\t0.45\\t0.249\\t0.132 🔻\\nsofa\\t        0.064\\t0.231\\t0.093\\t0.037 ❌\\npillar\\t        0.112\\t0.111\\t0.073\\t0.025 ❌\\ncabinet\\t        0.803\\t1.0\\t    0.995\\t0.796 ✅ (але тільки 1 приклад)\\n\\nmAP@0.5 = 0.48 — цілком прийнятний для невеликого або складного датасету, особливо з 10 класами.\\n\\nmAP@0.5:0.95 = 0.305 — традиційно нижчий, бо тут метрика жорсткіша (враховує IoU від 0.5 до 0.95).\\n\\nPrecision низький, Recall вищий — модель часто виявляє об\\'єкти (хороший Recall), але багато помилково класифікує (низький Precision). Це може бути через:\\n\\nПерекриття класів (наприклад, door vs open_door).\\nПогану або неоднозначну розмітку.\\nМодель «перестраховується» і видає багато позитивних детекцій.\\n\\nКласи open_door, cabinet_door, cabinet — найкраще навчені. Можливо, там більше якісних прикладів.\\n\\nПроблемні класи: sofa, pillar, chair, fridge_door — усі мають низькі метрикию.\\nМожливі причини:\\n\\nМало прикладів в тренувальному датасеті.\\nНепослідовна або низькоякісна розмітка.\\nКласи важко відрізнити візуально (зокрема, chair vs sofa або pillar).\\nЗанадто складна структура цих класів для обраної моделі.\\n\\nЗаключення:\\nОтримані метрики — відповідають очікуванням для базової моделі на складному датасеті. Основна робота — поліпшення даних та глибше тюнінг архітектури.\\n\\n\\n2. Оцінка архітектури моделі\\nОбрана модель — YOLOv9s:\\n\\nПереваги:\\nЛегка та швидка, з відносно невеликою кількістю параметрів (~7 млн).\\nПідходить для тренування на невеликих і середніх датасетах.\\nДобре працює на швидкість і баланс точності.\\n\\nМожливі недоліки:\\nМодель \"small\" може не мати достатньо складної архітектури для розпізнавання тонких відмінностей між схожими класами (door vs open_door, chair vs sofa).\\nОбмежена здатність до узагальнення на класи з малою кількістю даних.\\nВикористання фіксованого розміру зображення (640x640) може погано відображати дрібні деталі.\\n\\n3. Шляхи покращення\\n3.1. Оптимізація датасету\\nЗбільшити кількість зразків проблемних класів (sofa, pillar, chair, fridge_door).\\nПеревірити та покращити якість розмітки, особливо в проблемних класах.\\nВиконати аугментації (горизонтальні/вертикальні дзеркала, повороти, зміна яскравості) — допоможе уникнути перенавчання.\\n\\n3.2. Архітектура та тренування\\nСпробувати більш потужні версії YOLO (наприклад, YOLOv9m, YOLOv9l) — більша глибина мережі допоможе розпізнавати складні патерни.\\nВикористати додаткові методи регуляризації: DropBlock, label smoothing, MixUp.\\nЗмінити розмір зображень під час тренування — наприклад, збільшити до 768 чи 1024 для кращої деталізації.\\nВиконати fine-tuning з попередньо натренованою моделлю на великому датасеті (наприклад, COCO).\\n\\n3.3. Метрики і постобробка\\nПідібрати оптимальний поріг confidence та NMS (non-max suppression) — це може зменшити помилки класифікації.\\nАналізувати помилки за допомогою confusion matrix, виявити, які класи плутаються, і сконцентруватися на їх розділенні.\\n\\n3.4. Альтернативні підходи\\nВикористати інші архітектури, наприклад, EfficientDet або Cascade R-CNN, для кращої точності.\\nВикористати ансамблі моделей.\\nВпровадити двокроковий підхід: спершу детекція об\\'єктів, потім класифікація на підкласи.\\n\\n4. Загальний висновок:\\n\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "''' \n",
    "1. Аналіз отриманих результатів\n",
    "1 навчання\n",
    "\n",
    "Метрика\t      Значення\n",
    "mAP@0.5\t        0.48\n",
    "mAP@0.5:0.95\t0.305\n",
    "Precision (P)\t0.385\n",
    "Recall (R)\t    0.567\n",
    "\n",
    "2 навчання\n",
    "Метрика\t        Значення\n",
    "mAP@0.5\t        0.48\n",
    "mAP@0.5:0.95\t0.304\n",
    "Precision (P)\t0.385\n",
    "Recall (R)\t    0.567\n",
    "\n",
    "\n",
    "Клас\t          P\t    R\t    mAP@0.5\tmAP@0.5:0.95\n",
    "open_door\t    0.631\t0.818\t0.811\t0.465 ✅\n",
    "cabinet_door\t0.610\t0.714\t0.682\t0.464 ✅\n",
    "window\t        0.477\t0.653\t0.615\t0.347 👍\n",
    "table\t        0.281\t0.625\t0.489\t0.294\n",
    "door\t        0.35\t0.629\t0.504\t0.316\n",
    "fridge_door\t    0.311\t0.44\t0.29\t0.174 🔻\n",
    "chair\t        0.206\t0.45\t0.249\t0.132 🔻\n",
    "sofa\t        0.064\t0.231\t0.093\t0.037 ❌\n",
    "pillar\t        0.112\t0.111\t0.073\t0.025 ❌\n",
    "cabinet\t        0.803\t1.0\t    0.995\t0.796 ✅ (але тільки 1 приклад)\n",
    "\n",
    "mAP@0.5 = 0.48 — цілком прийнятний для невеликого або складного датасету, особливо з 10 класами.\n",
    "\n",
    "mAP@0.5:0.95 = 0.305 — традиційно нижчий, бо тут метрика жорсткіша (враховує IoU від 0.5 до 0.95).\n",
    "\n",
    "Precision низький, Recall вищий — модель часто виявляє об'єкти (хороший Recall), але багато помилково класифікує (низький Precision). Це може бути через:\n",
    "\n",
    "Перекриття класів (наприклад, door vs open_door).\n",
    "Погану або неоднозначну розмітку.\n",
    "Модель «перестраховується» і видає багато позитивних детекцій.\n",
    "\n",
    "Класи open_door, cabinet_door, cabinet — найкраще навчені. Можливо, там більше якісних прикладів.\n",
    "\n",
    "Проблемні класи: sofa, pillar, chair, fridge_door — усі мають низькі метрикию.\n",
    "Можливі причини:\n",
    "\n",
    "Мало прикладів в тренувальному датасеті.\n",
    "Непослідовна або низькоякісна розмітка.\n",
    "Класи важко відрізнити візуально (зокрема, chair vs sofa або pillar).\n",
    "Занадто складна структура цих класів для обраної моделі.\n",
    "\n",
    "Заключення:\n",
    "Отримані метрики — відповідають очікуванням для базової моделі на складному датасеті. Основна робота — поліпшення даних та глибше тюнінг архітектури.\n",
    "\n",
    "\n",
    "2. Оцінка архітектури моделі\n",
    "Обрана модель — YOLOv9s:\n",
    "\n",
    "Переваги:\n",
    "Легка та швидка, з відносно невеликою кількістю параметрів (~7 млн).\n",
    "Підходить для тренування на невеликих і середніх датасетах.\n",
    "Добре працює на швидкість і баланс точності.\n",
    "\n",
    "Можливі недоліки:\n",
    "Модель \"small\" може не мати достатньо складної архітектури для розпізнавання тонких відмінностей між схожими класами (door vs open_door, chair vs sofa).\n",
    "Обмежена здатність до узагальнення на класи з малою кількістю даних.\n",
    "Використання фіксованого розміру зображення (640x640) може погано відображати дрібні деталі.\n",
    "\n",
    "3. Шляхи покращення\n",
    "3.1. Оптимізація датасету\n",
    "Збільшити кількість зразків проблемних класів (sofa, pillar, chair, fridge_door).\n",
    "Перевірити та покращити якість розмітки, особливо в проблемних класах.\n",
    "Виконати аугментації (горизонтальні/вертикальні дзеркала, повороти, зміна яскравості) — допоможе уникнути перенавчання.\n",
    "\n",
    "3.2. Архітектура та тренування\n",
    "Спробувати більш потужні версії YOLO (наприклад, YOLOv9m, YOLOv9l) — більша глибина мережі допоможе розпізнавати складні патерни.\n",
    "Використати додаткові методи регуляризації: DropBlock, label smoothing, MixUp.\n",
    "Змінити розмір зображень під час тренування — наприклад, збільшити до 768 чи 1024 для кращої деталізації.\n",
    "Виконати fine-tuning з попередньо натренованою моделлю на великому датасеті (наприклад, COCO).\n",
    "\n",
    "3.3. Метрики і постобробка\n",
    "Підібрати оптимальний поріг confidence та NMS (non-max suppression) — це може зменшити помилки класифікації.\n",
    "Аналізувати помилки за допомогою confusion matrix, виявити, які класи плутаються, і сконцентруватися на їх розділенні.\n",
    "\n",
    "3.4. Альтернативні підходи\n",
    "Використати інші архітектури, наприклад, EfficientDet або Cascade R-CNN, для кращої точності.\n",
    "Використати ансамблі моделей.\n",
    "Впровадити двокроковий підхід: спершу детекція об'єктів, потім класифікація на підкласи.\n",
    "\n",
    "4. Загальний висновок:\n",
    "Тренування моделі - потребує найбільшого ресурсу. \n",
    "Графіки та тестові/валідаційні малюнки додані в папку \"indoor_yolov9s63\".\n",
    "Навчана модель збережена в файл \"yolov9s.pt\" та займає дуже великий обсяг.\n",
    "Вперше використовую файл конфігурації \"indoor.yaml\" для навчання моделі.\n",
    "Дуже цікавий досвід. Дякую.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
